{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean-up data\n",
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from pandas import to_numeric\n",
    "\n",
    "# fill missing values with a value at the same time one day ago\n",
    "def fill_missing(values):\n",
    "    one_day = 60 * 24\n",
    "    for row in range(values.shape[0]):\n",
    "        for col in range(values.shape[1]):\n",
    "            if isnan(values[row, col]):\n",
    "                values[row, col] = values[row - one_day, col]\n",
    "\n",
    "# load all data\n",
    "dataset = read_csv('household_power_consumption.txt', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n",
    "# mark all missing values\n",
    "dataset.replace('?', nan, inplace=True)\n",
    "# make dataset numeric\n",
    "dataset = dataset.astype('float32')\n",
    "# fill missing\n",
    "fill_missing(dataset.values)\n",
    "# add a column for for the remainder of sub metering\n",
    "values = dataset.values\n",
    "dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])\n",
    "# save updated dataset\n",
    "dataset.to_csv('household_power_consumption.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "1. Problem Framing\n",
    "2. Evaluation Metric\n",
    "3. Train and Test Sets\n",
    "4. Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem Framing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample the per-minute observations of power consumption to daily totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442, 8)\n",
      "            Global_active_power  Global_reactive_power    Voltage  \\\n",
      "datetime                                                            \n",
      "2006-12-16             1209.176                 34.922   93552.53   \n",
      "2006-12-17             3390.460                226.006  345725.32   \n",
      "2006-12-18             2203.826                161.792  347373.64   \n",
      "2006-12-19             1666.194                150.942  348479.01   \n",
      "2006-12-20             2225.748                160.998  348923.61   \n",
      "\n",
      "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
      "datetime                                                                       \n",
      "2006-12-16            5180.8             0.0           546.0          4926.0   \n",
      "2006-12-17           14398.6          2033.0          4187.0         13341.0   \n",
      "2006-12-18            9247.2          1063.0          2621.0         14018.0   \n",
      "2006-12-19            7094.0           839.0          7602.0          6197.0   \n",
      "2006-12-20            9313.0             0.0          2648.0         14063.0   \n",
      "\n",
      "            sub_metering_4  \n",
      "datetime                    \n",
      "2006-12-16    14680.933319  \n",
      "2006-12-17    36946.666732  \n",
      "2006-12-18    19028.433281  \n",
      "2006-12-19    13131.900043  \n",
      "2006-12-20    20384.800011  \n"
     ]
    }
   ],
   "source": [
    "# resample minute data to total for each day\n",
    "from pandas import read_csv\n",
    "# load the new file\n",
    "dataset = read_csv('household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# resample data to daily\n",
    "daily_groups = dataset.resample('D')\n",
    "daily_data = daily_groups.sum()\n",
    "# summarize\n",
    "print(daily_data.shape)\n",
    "print(daily_data.head())\n",
    "# save\n",
    "daily_data.to_csv('household_power_consumption_days.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Given a standard feed-forward multilayer Perceptron network, a recurrent neural network can be thought of as the addition of loops to the architecture. For example, in a given layer, each neuron may pass its signal latterly (sideways) in addition to forward to the next layer. The output of the network may feedback as an input to the network with the next input vector. And so on.\n",
    "\n",
    "__Two major issues__\n",
    "1. How to train the network with Backpropagation.\n",
    "2. How to stop gradients vanishing or exploding during training.\n",
    "\n",
    "__1. How to Train Recurrent Neural Networks__\n",
    "\n",
    "Backpropagation breaks down in a recurrent neural network, because of the recurrent or loop connections.\n",
    "\n",
    "To resolve it, the structure of the network is unrolled, where copies of the neurons that have recurrent connections are created. For example a single neuron with a connection to itself (A->A) could be represented as two neurons with the same weight values (A->B).\n",
    "\n",
    "This allows the cyclic graph of a recurrent neural network to be turned into an acyclic graph like a classic feed-forward neural network, and Backpropagation can be applied.\n",
    "\n",
    "__2. How to Have Stable Gradients During Training__\n",
    "\n",
    "Unrolled recurrent neural networks can become very large numbers called exploding gradients or very small numbers called the vanishing gradient problem.\n",
    "\n",
    "In recurrent neural network architectures, this problem has been alleviated using a new type of architecture called the Long Short-Term Memory Networks that allows deep recurrent networks to be trained.\n",
    "\n",
    "## Long Short-Term Memory Networks\n",
    "\n",
    "The Long Short-Term Memory or LSTM network is a recurrent neural network that is trained using Backpropagation Through Time and overcomes the vanishing gradient problem.\n",
    "\n",
    "Instead of neurons, LSTM networks have memory blocks that are connected into layers.\n",
    "\n",
    "A block has components that make it smarter than a classical neuron and a memory for recent sequences. A block contains gates that manage the blockâ€™s state and output. A unit operates upon an input sequence and each gate within a unit uses the sigmoid activation function to control whether they are triggered or not, making the change of state and addition of information flowing through the unit conditional.\n",
    "\n",
    "There are three types of gates within a memory unit:\n",
    "- __Forget Gate__: conditionally decides what information to discard from the unit.\n",
    "- __Input Gate__: conditionally decides which values from the input to update the memory state.\n",
    "- __Output Gate__: conditionally decides what to output based on input and the memory of the unit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
