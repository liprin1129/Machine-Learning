{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction to Keras](#Introduction to Keras)\n",
    "    1. [Sequential Model](#Sequential Model)\n",
    "    2. [Layer](#Layer)\n",
    "    3. [Convolutions](#convolutions)\n",
    "    4. [Pooling](#Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Keras <a name='Introduction to Keras'></a>\n",
    "\n",
    "### 1. Sequential Model <a name='Sequential Model'></a>\n",
    "\n",
    "The [keras.models.Sequential](https://keras.io/models/sequential/) class is a wrapper for the neural network model. It provides common functions like __fit()__, __evaluate()__, and __compile()__. Let's start looking at the layers of the model to understand these functions.\n",
    "\n",
    "```Python\n",
    "from keras.models import Sequential\n",
    "\n",
    "#Create the Sequential model\n",
    "model = Sequential()\n",
    "```\n",
    "\n",
    "### 2. Layer <a name='Layer'></a>\n",
    "A Keras layer is just like a neural network layer. There are fully connected layers, max pool layers, and activation layers. We can add a layer to the model using the model's __add()__ function. For example, a simple model would look like this:\n",
    "\n",
    "```Python\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "#Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "#1st Layer - Add a flatten layer\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "\n",
    "#2nd Layer - Add a fully connected layer\n",
    "model.add(Dense(100))\n",
    "\n",
    "#3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#4th Layer - Add a fully connected layer\n",
    "model.add(Dense(60))\n",
    "\n",
    "#5th Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "```\n",
    "\n",
    "Keras will automatically infer the shape of all layers after the first layer. This means you only have to set the input dimensions for the first layer.\n",
    "\n",
    "The first layer from above, __model.add(Flatten(input_shape=(32, 32, 3)))__, sets the input dimension to __(32, 32, 3)__ and output dimension to __(3072=32 x 32 x 3)__. The second layer takes in the output of the first layer and sets the output dimensions to (100). This chain of passing output to the next layer continues until the last layer, which is the output of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__Quiz:__\n",
    "Build a multi-layer feedforward neural network to classify traffic sign images using Keras.\n",
    "\n",
    "- Set the first layer to a __Flatten()__ layer with the __input_shape__ set to (32, 32, 3).\n",
    "- Set the second layer to a __Dense()__ layer with an output width of 128.\n",
    "- Use a ReLU activation function after the second layer.\n",
    "- Set the output layer width to 5, because for this data set there are only 5 classes.\n",
    "- Use a softmax activation function after the output layer.\n",
    "- Train the model for 3 epochs. You should be able to get over 50% training accuracy.\n",
    "\n",
    "To get started, review the Keras documentation about models and layers. The Keras example of a [Multi-Layer Perceptron](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py) network is similar to what we need to do here. Use that as a guide, but keep in mind that there are a number of differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('../../Data/Face/small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(np.max(X_train[0]), np.min(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0]*255)\n",
    "print(np.shape(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "np.shape(y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face-object data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32, 3) (100, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "with open('../../../Data/Face/faces-obj-32x32-features-norm.pkl', mode='rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "    X_train = X_train[:100]\n",
    "    \n",
    "with open('../../../Data/Face/faces-obj-32x32-labels-norm.pkl', mode='rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "    y_train = y_train[:100]\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0])\n",
    "print(np.shape(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.asarray(y_train, dtype=np.uint8)\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = X_train\n",
    "y_one_hot=y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "y_one_hot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_one_hot)\n",
    "y_one_hot = enc.transform(y_one_hot).toarray()\n",
    "y_one_hot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "# TODO: Build the Fully Connected Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# preprocess data\n",
    "# X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "# TODO: change the number of training epochs to 3\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__\n",
    "```Python\n",
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "# Build the Fully Connected Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=3, validation_split=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. convolutions <a name='convolutions'></a>\n",
    "\n",
    "__Quiz:__\n",
    "- Build from the previous network.\n",
    "- Add a convolutional layer with 32 filters, a 3x3 kernel, and valid padding before the flatten layer.\n",
    "- Add a ReLU activation after the convolutional layer.\n",
    "- Train for 3 epochs again, should be able to get over 50% accuracy.\n",
    "\n",
    "Hint 1: The Keras example of a convolutional neural network for MNIST would be a good example to review.\n",
    "Hint 2: We can set the padding type by passing in a border_mode= argument to the Convolution2D() layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/mnt/SharedData/Development/PythonEnvs/3.5PyEnv/lib/python3.5/site-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.2863 - acc: 0.5000 - val_loss: 0.5865 - val_acc: 0.7000\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s 227us/step - loss: 0.6495 - acc: 0.5375 - val_loss: 0.6283 - val_acc: 0.5500\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s 227us/step - loss: 0.4837 - acc: 0.7625 - val_loss: 0.7989 - val_acc: 0.3000\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s 254us/step - loss: 0.3962 - acc: 0.7500 - val_loss: 0.4262 - val_acc: 0.8500\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s 234us/step - loss: 0.2211 - acc: 0.9875 - val_loss: 0.2611 - val_acc: 0.9500\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s 266us/step - loss: 0.1269 - acc: 0.9875 - val_loss: 0.3436 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s 240us/step - loss: 0.0807 - acc: 0.9750 - val_loss: 0.1678 - val_acc: 0.9500\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0685 - acc: 0.9750 - val_loss: 0.2729 - val_acc: 0.8500\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s 271us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.2371 - val_acc: 0.9000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s 251us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.2157 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n",
    "# TODO: Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "#model.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Preprocess data\n",
    "# X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__\n",
    "\n",
    "```Python\n",
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n",
    "# Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling <a name='Pooling'></a>\n",
    "\n",
    "__Quiz:__\n",
    "\n",
    "- Build from the previous network\n",
    "- Add a 2x2 max pooling layer immediately following the convolutional layer.\n",
    "- Train for 3 epochs again to be able to get over 50% training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "# TODO: Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__\n",
    "```Python\n",
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "# Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "__Quiz:__\n",
    "- Build from the previous network.\n",
    "- Add a dropout layer after the pooling layer. Set the dropout rate to 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "# TODO: Build Convolutional Pooling Neural Network with Dropout in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test In Keras\n",
    "\n",
    "Pick out your best model, it's time to test it!\n",
    "\n",
    "- Try to get the highest validation accuracy possible. Feel free to use all the previous concepts and train for as many epochs as needed.\n",
    "- Select the best model and train it one more time.\n",
    "- Use the test data and the Keras [evaluate()](https://keras.io/models/model/#evaluate) method to see how well the model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('datasets/small_traffic_set/small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "# TODO: Build the Final Test Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=10, validation_split=0.2)\n",
    "\n",
    "with open('datasets/small_traffic_set/small_test_traffic.p', 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "X_test = data_test['features']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "# preprocess data\n",
    "X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "print(\"Testing\")\n",
    "\n",
    "# TODO: Evaluate the test data in Keras Here\n",
    "metrics = model.evaluate(X_normalized_test, y_one_hot_test)\n",
    "# TODO: UNCOMMENT CODE\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0])\n",
    "\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "plt.imshow(X_normalized[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
