{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert matlab data to jpg image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/user170/shared-data/Personal_Dev/Machine-Learning/Data/Depth/NYU-Depth-Dataset-V2/\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with h5py.File(data_folder+'nyu_depth_v2_labeled.mat', 'r') as mat_data:\n",
    "    #print(mat_data['images'][0].astype(np.uint8))\n",
    "    #print(mat_data['depths'][0])\n",
    "    print(np.shape(mat_data['images'][0]))\n",
    "    pil_img = np.moveaxis(mat_data['images'][1], [0, 1], [-1, -2])\n",
    "    pil_img = Image.fromarray(pil_img)\n",
    "    print(pil_img)\n",
    "    \n",
    "    plt.imshow(pil_img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with h5py.File(data_folder+'nyu_depth_v2_labeled.mat', 'r') as mat_data:\n",
    "    \n",
    "    print(np.shape(mat_data['depths'][0]))\n",
    "    #pil_img = np.moveaxis(mat_data['depths'][1], [0, 1], [-1, -2])\n",
    "    pil_img = np.moveaxis(mat_data['depths'][1], [0], [-1])\n",
    "    #pil_img = Image.fromarray(pil_img)\n",
    "    #print(np.shape(pil_img))\n",
    "    #pil_img.save(data_folder+\"Images/Depth/depth.tiff\", \"TIFF\")\n",
    "    #plt.imshow(pil_img)\n",
    "    \n",
    "    import cv2\n",
    "    cv2.imwrite(data_folder+\"Images/Depth/depth.png\", pil_img*80)\n",
    "    \n",
    "    #new_img = pil_img#np.asarray(pil_img, np.int)\n",
    "    #new_img = np.stack([new_img*50, new_img*60, new_img*70])\n",
    "    #new_img = np.moveaxis(new_img, 0, -1)\n",
    "    #print(new_img.shape)\n",
    "    #plt.imshow(np.asarray(new_img, np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_folder+'nyu_depth_v2_labeled.mat', 'r') as mat_data:\n",
    "    data_len = len(mat_data['images'])\n",
    "    \n",
    "    for idx in range(data_len):\n",
    "        #rgb_img = Image.fromarray(np.moveaxis(mat_data['images'][idx], [0, 1], [-1, -2]))\n",
    "        depth_img = Image.fromarray(np.moveaxis(mat_data['depths'][idx], [0], [-1]), mode='F')\n",
    "\n",
    "        '''\n",
    "        if rgb_img.mode != \"RGB\":\n",
    "            rgb_img = rgb_img.convert(\"RGB\")\n",
    "        \n",
    "        if depth_img.mode != \"RGB\":\n",
    "            depth_img = depth_img.convert(\"RGB\")\n",
    "        '''\n",
    "        \n",
    "        #rgb_img.save(data_folder+\"Images/RGB/{0}.jpg\".format(idx))\n",
    "        depth_img.save(data_folder+\"Images/Depth/{0}.tiff\".format(idx), \"TIFF\")\n",
    "\n",
    "    #[Image.fromarray(i) for i in mat_data['images']]\n",
    "    #image_data = mat_data['images']\n",
    "    #depths_data = mat_data['depths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "with h5py.File(data_folder+'nyu_depth_v2_labeled.mat', 'r') as mat_data:\n",
    "    data_len = len(mat_data['images'])\n",
    "    \n",
    "    for idx in range(data_len):\n",
    "        #rgb_img = Image.fromarray(np.moveaxis(mat_data['images'][idx], [0, 1], [-1, -2]))\n",
    "        depth_img = np.moveaxis(mat_data['depths'][idx], [0], [-1])\n",
    "        cv2.imwrite(data_folder+\"Images/Depth/PNG/{0}.png\".format(idx), depth_img*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(data_folder+\"Images/Depth/depth.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/user170/shared-data/Personal_Dev/Machine-Learning/Data/Depth/NYU-Depth-Dataset-V2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData(Dataset):\n",
    "    def __init__(self, mat_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mat_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.mat_data = h5py.File(root_dir+mat_file, 'r')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        self.dataset_len = len(self.mat_data['images'])\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, train_test_ratio = 0.3):\n",
    "        # shuffle indice\n",
    "        rnd_idx = np.random.shuffle(np.arrange(self.dataset_len))\n",
    "        # set the barrier between train and validation dataset\n",
    "        split_thresh = self.dataset_len*int(1-0.3)\n",
    "        \n",
    "        train_idx = rnd_idx[:split_thresh]\n",
    "        test_idx = rand_idx[split_thresh:]\n",
    "        \n",
    "        image = self.mat_data['images'][train_idx]\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = LoadData(\n",
    "    \"nyu_depth_v2_labeled.mat\", \n",
    "    \"/home/user170/shared-data/Personal_Dev/Machine-Learning/Data/Depth/NYU-Depth-Dataset-V2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.__getitem__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_folder+'nyu_depth_v2_labeled.mat', 'r') as mat_data:\n",
    "    image_data = mat_data['images']\n",
    "    depths_data = mat_data['depths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data = h5py.File(data_folder+'nyu_depth_v2_labeled.mat', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([mat_data['images'], mat_data['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mat_data['images'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
