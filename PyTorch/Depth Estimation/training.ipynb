{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import Image\n",
    "from skimage import io, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert matlab data to jpg image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/user170/shared-data/Personal_Dev/Machine-Learning/Data/Depth/NYU-Depth-Dataset-V2/\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with h5py.File(data_folder+'nyu_depth_v2_labeled.mat', 'r') as mat_data:\n",
    "    data_len = len(mat_data['images'])\n",
    "    \n",
    "    for idx in range(data_len):\n",
    "        rgb_img = Image.fromarray(np.moveaxis(mat_data['images'][idx], [0, 1], [-1, -2]))\n",
    "        depth_img = Image.fromarray(np.moveaxis(mat_data['depths'][idx], [0], [-1]), mode='F')\n",
    "        \n",
    "        rgb_img.save(data_folder+\"Images/RGB/{0:04d}.jpg\".format(idx))\n",
    "        depth_img.save(data_folder+\"Images/Depth-TIFF/{0:04d}.tiff\".format(idx), \"TIFF\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Convert float to png using opencv\n",
    "import cv2\n",
    "\n",
    "with h5py.File(data_folder+'nyu_depth_v2_labeled.mat', 'r') as mat_data:\n",
    "    data_len = len(mat_data['images'])\n",
    "    \n",
    "    for idx in range(data_len):\n",
    "        #rgb_img = Image.fromarray(np.moveaxis(mat_data['images'][idx], [0, 1], [-1, -2]))\n",
    "        depth_img = np.moveaxis(mat_data['depths'][idx], [0], [-1])\n",
    "        cv2.imwrite(data_folder+\"Images/Depth/PNG/{0}.png\".format(idx), depth_img*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = Image.open(data_folder+\"Images/RGB/0000.jpg\")\n",
    "d_img = Image.open(data_folder+\"Images/Depth-TIFF/0000.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d_img)\n",
    "print(np.max(d_img))\n",
    "print(np.min(d_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#sorted(os.listdir(data_folder+\"Images/Depth-TIFF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData(Dataset):\n",
    "    def __init__(self, root_dir, testset_ratio=0.3, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with RGB and Depth-TIFF images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        #self.mat_data = h5py.File(root_dir+mat_file, 'r')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.testset_ratio = testset_ratio\n",
    "        \n",
    "        self.trainset_idx, self.testset_idx, self.trainset_num, self.testset_num = self._seperate_dataset()\n",
    "\n",
    "    def _seperate_dataset(self):\n",
    "        \"\"\"\n",
    "        Seperate Train and Test dataset\n",
    "        \n",
    "        Returns: random indice of train test datasets, and lend of those.\n",
    "        \"\"\"\n",
    "        dataset_len = len(os.listdir(self.root_dir+\"Images/RGB/\"))\n",
    "        rnd_idx = [i for i in range(dataset_len)]\n",
    "        np.random.shuffle(rnd_idx)\n",
    "        split_thresh = int(dataset_len*(1-self.testset_ratio))\n",
    "\n",
    "        train_idx = rnd_idx[:split_thresh]\n",
    "        test_idx = rnd_idx[split_thresh:]\n",
    "\n",
    "        trainset_num = len(train_idx)\n",
    "        testset_num = len(test_idx)\n",
    "\n",
    "        return train_idx, test_idx, trainset_num, testset_num\n",
    "    \n",
    "    def __len__(self):\n",
    "        self.dataset_len = len(os.listdir(self.root_dir+\"Images/RGB/\"))\n",
    "        return self.dataset_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rgb_img = Image.open(self.root_dir+'Images/RGB/{0:04d}.jpg'.format(self.trainset_idx[idx]))\n",
    "        depth_img = Image.open(self.root_dir+'Images/Depth-TIFF/{0:04d}.tiff'.format(self.trainset_idx[idx]))\n",
    "        \n",
    "        sample = {'RGB':rgb_img, 'DEPTH':depth_img}\n",
    "            \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = LoadData(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trainloader)):\n",
    "    sample = trainloader[i]\n",
    "    print(i, \n",
    "          '[RGB u: {:.2f}, std: {:.2f}]'.format(np.mean(sample['RGB']), np.std(sample['RGB'])),\n",
    "          '\\t[DEPTH u: {:.2f}, std: {:.2f}]'.format(np.mean(sample['DEPTH']), np.std(sample['DEPTH'])))\n",
    "    \n",
    "    if i == 3:\n",
    "        #plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarray in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        rgb_img, depth_img = sample['RGB'], sample['DEPTH']\n",
    "        \n",
    "        # swap colour axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        rgb_img = np.moveaxis(np.asarray(rgb_img), [0], [-0])\n",
    "        depth_img = np.asarray(depth_img)\n",
    "        \n",
    "        return {'RGB': torch.from_numpy(rgb_img), 'DEPTH': torch.from_numpy(depth_img)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = ToTensor()\n",
    "plt.imshow(to_tensor(train[0])['RGB'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = transforms.Compose([ToTensor()])\n",
    "print(type(composed(train[0])['RGB'])\n",
    "plt.imshow(composed(train[0])['RGB'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(composed(train[0])['RGB'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using class function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = LoadData(root_dir=data_folder, transform=composed)\n",
    "\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "plt.imshow(load_data[0]['RGB'].numpy())\n",
    "ax = plt.subplot(2, 1, 2)\n",
    "plt.imshow(load_data[0]['DEPTH'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(load_data[0]['RGB'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make normalization class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
