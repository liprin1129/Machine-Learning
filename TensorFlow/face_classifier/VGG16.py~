# IMPORT TENSORFLOW
import tensorflow as tf
#from tensorflow.contrib.layers import flatten

# IMPORT NECCESSARY PACKAGES
import numpy as np
from tqdm import tqdm

class net_setup(object):
    def __init__(self):
        # Net info.
        self.learning_rate = 0.5
        self.epoch = 5000
        self.batch_size = 50
        self.keep_prob_node = tf.placeholder(tf.float32)
        
        # Network shapes
        self.kernel_1x1 = 1
        self.kernel_3x3 = 3
        
        self.depth1 = 12
        self.depth2 = 24
        self.depth3 = 48
        self.depth4 = 96
        self.depth5 = 192

        self.dense_4096 = 4096
        self.dense_1000 = 1000
        self.dense_output = 2

    @classmethod
    def filter_var(cls, kernel, in_depth, out_depth, node_name):
        return tf.Variable(
            tf.truncated_normal((kernel, kernel, in_depth, out_depth), stddev=0.1, dtype=tf.float32),
            name=node_name+"_filter")
    
    def bias_var(cls, size, node_name):
        return tf.Variable(
            tf.zeros([size], dtype=tf.float32), 
            name=node_name+"_bias")

    def dense_var(cls, in_size, out_size, node_name):
        return tf.Variable(
            tf.truncated_normal([in_size, out_size], stddev=0.1, dtype=tf.float32),
            name=node_name+"_dense")
    
    def max_pool(cls, in_node, node_name):
        return tf.nn.max_pool(in_node, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=node_name)

class VGG16(net_setup):
    def __init__(self, features, labels):
        super(VGG16, self).__init__()

        self.__features, self.__feature_shape = self.reshape_for_tensor(features)
        self.__labels = labels
        self.__labels_shape = (None, np.shape(labels)[1])

        # For networks
        self.__logits_node = None
        self.__cost_function_node = None
        self.__optimizer_node = None
        self.__correct_prediction_node = None
        self.__accuracy_node = None


    def input_node(self, data_shape):
        '''
        img_shape = np.shape(in_data)
 
        if len(img_shape) < 4:
            in_data = np.reshape(in_data, (-1, np.shape(in_data)[1], np.shape(in_data)[2], 1))
            img_shape = np.shape(in_data)
 
        img_shape = (None, np.shape(in_data)[1], np.shape(in_data)[2], np.shape(in_data)[3])
    
        assert len(img_shape) == 4, (
            "\nCUSTOM ERROR! ---> Input data shape isn't correct. The shape is {shape}".format(shape=img_shape))
        '''
        #_, img_shape = self.reshape_for_tensor(in_data)
        
        return tf.placeholder(tf.float32, shape=data_shape)

    def convolutional_node(self, in_node, kernel_size, out_depth, name):
        with tf.variable_scope(name):
            conv_filter = self.filter_variable(
                kernel = kernel_size,
                in_depth=in_node.get_shape().as_list()[-1],
                out_depth=out_depth,
                node_name=name)
            #print(conv_filter.shape)
            conv_bias = self.bias_variable(size=out_depth, node_name=name)
            #print(conv_bias.shape)

            conv = tf.nn.conv2d(in_node, conv_filter, [1, 1, 1, 1], padding="SAME")
            conv = tf.nn.bias_add(conv, conv_bias)
            conv = tf.nn.relu(conv)

            return conv

    def dense_node(self, in_node, dense_size, name):
        #print(in_node.get_shape().as_list())
        dense_weight = self.dense_variable(in_size=in_node.get_shape().as_list()[-1], out_size=dense_size, node_name=name)
        dense_bias = self.bias_variable(size=dense_size, node_name=name)
        return tf.nn.relu(tf.add(tf.matmul(in_node, dense_weight), dense_bias))
